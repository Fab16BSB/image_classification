{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## üìö Additional Libraries Import\n",
    "\n",
    "We import some additional libraries used throughout the project for various purposes:\n",
    "- File and directory operations (`os`, `shutil`)\n",
    "- Numerical computations with arrays (`numpy`)\n",
    "- Handling JSON files (`json`)\n",
    "- Loading Keras models from JSON (`tensorflow.keras.models.model_from_json`)\n",
    "- Image processing and annotation (`PIL` ‚Äî `Image`, `ImageDraw`, `ImageFont`)\n",
    "- Image preprocessing for deep learning (`tensorflow.keras.preprocessing.image.img_to_array`)\n",
    "- Activation functions from Keras (`tensorflow.keras.activations`)\n",
    "- Plotting and visualization (`matplotlib.pyplot`)\n"
   ],
   "metadata": {
    "id": "O4DAWggUPG0u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import activations\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "id": "YLCjpJCJxUcG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ‚öôÔ∏è Paths and Parameters for Prediction\n",
    "\n",
    "This section defines the key variables used during the prediction phase:\n",
    "\n",
    "- **Model path** where the saved model files are located  \n",
    "- **Dataset path** pointing to the base folder of the image dataset  \n",
    "- **Prediction directories** as a list of paths containing images to classify  \n",
    "- **Loaded model name** to identify which trained model to load  \n",
    "- **Classification mode** (`multi_class`) to specify if the task is multi-class or not  \n",
    "- **Confidence threshold** to filter predictions based on probability\n"
   ],
   "metadata": {
    "id": "HEV2vdYIPNmO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path_model = \"modele/dragonball\"                  # Path where the model file will be saved\n",
    "path_data = \"data/dragonball/\"                    # Path to the image dataset\n",
    "\n",
    "predict_data_dir = [path_data + \"predict/\"]       # List of paths to prediction images\n",
    "loaded_model_name = \"dragonball_model\"            # Name of the model to be loaded\n",
    "multi_class = False                               # Set to True for multi-class classification\n",
    "threshold = 0.75                                  # Confidence threshold for prediction\n",
    "\n",
    "# Prediction and label storage\n",
    "predict_file_list = []"
   ],
   "metadata": {
    "id": "uuNxG5wFvHRl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üîÑ Loading Pretrained Models\n",
    "\n",
    "This section covers how to load a pretrained Keras model from saved files, including:\n",
    "\n",
    "- Loading the model architecture from a JSON file  \n",
    "- Loading the model weights from an HDF5 file\n",
    "- Loading the labels from a TXT file  \n",
    "- Combining both to restore the complete model for inference or further training  \n"
   ],
   "metadata": {
    "id": "0h9uhzjbuV9F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vrejVZuuQ40",
    "outputId": "63808563-22ff-40ec-aef4-08e35a14538e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loaded from modele/dragonball/dragonball_model.json and modele/dragonball/dragonball_model.weights.h5\n",
      "Labels loaded from modele/dragonball/labels.txt: ['gohan', 'goku', 'piccolo', 'vegeta']\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_dir(model_dir, model_name, labels_filename=\"labels.txt\"):\n",
    "    \"\"\"\n",
    "    Load a Keras model and class labels from files in a specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir: str, path to the directory containing model files\n",
    "        model_name: str, base filename of the model (without extension)\n",
    "        labels_filename: str, filename of the labels text file (default \"labels.txt\")\n",
    "\n",
    "    Returns:\n",
    "        model: Keras model loaded with architecture and weights\n",
    "        labels: list of str, class labels loaded from the text file\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(model_dir, model_name + \".json\")\n",
    "    weights_path = os.path.join(model_dir, model_name + \".weights.h5\")\n",
    "    labels_path = os.path.join(model_dir, labels_filename)\n",
    "\n",
    "    # Load model architecture\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        model_json = json_file.read()\n",
    "    model = model_from_json(model_json)\n",
    "\n",
    "    # Load weights\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    print(f\"Model loaded from {json_path} and {weights_path}\")\n",
    "\n",
    "    # Load labels\n",
    "    if os.path.isfile(labels_path):\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels = [line.strip() for line in f.readlines()]\n",
    "        print(f\"Labels loaded from {labels_path}: {labels}\")\n",
    "    else:\n",
    "        labels = []\n",
    "        print(f\"Labels file not found at {labels_path}. Returning empty label list.\")\n",
    "\n",
    "    return model, labels\n",
    "\n",
    "# -- Execution section --\n",
    "model, label_list = load_model_from_dir(path_model, loaded_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üñºÔ∏è Image Prediction and Annotation\n",
    "\n",
    "In this section, we:\n",
    "\n",
    "- Gather all image files from the specified prediction directories.\n",
    "- For each image, preprocess and resize it to match the model input.\n",
    "- Use the trained model to predict class probabilities.\n",
    "- Annotate the original image with predicted class labels and their confidence scores.\n",
    "- Display images with prediction confidence above a defined threshold.\n",
    "- Organize predicted images into folders named by their predicted class for easier review.\n"
   ],
   "metadata": {
    "id": "Zac4i7bruZ-V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_predict_image_paths(predict_dirs):\n",
    "    \"\"\"\n",
    "    Collect and sort all image file paths from the prediction directories.\n",
    "\n",
    "    Args:\n",
    "        predict_dirs: list of directory paths to search for images.\n",
    "\n",
    "    Returns:\n",
    "        sorted list of image file paths with extensions png, jpg, jpeg.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    for path in predict_dirs:\n",
    "        if os.path.isdir(path):\n",
    "            all_files.extend([os.path.join(path, f) for f in os.listdir(path)])\n",
    "    all_files = sorted(all_files)\n",
    "\n",
    "    # Filter for image files only\n",
    "    image_files = [f for f in all_files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    return sorted(image_files)\n",
    "\n",
    "\n",
    "def predict_and_annotate_images(model, image_paths, labels, multi_class, predict_data_dir, threshold=90):\n",
    "    \"\"\"\n",
    "    Predict classes for a list of images, annotate each image with prediction probabilities,\n",
    "    and optionally save the annotated images into folders named by predicted class labels.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model used for prediction.\n",
    "        image_paths: List of file paths to the images to predict.\n",
    "        labels: List of class label strings.\n",
    "        multi_class: Boolean flag indicating if it is a multi-class classification task.\n",
    "        predict_data_dir: List of directories containing the prediction images.\n",
    "        threshold: Confidence threshold (percentage) above which to save annotated images.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    nameImg = 0  # Counter for naming saved images\n",
    "\n",
    "    print(\"Labels found:\", labels)\n",
    "\n",
    "    # 1. Determine the base directory to save results based on classification type\n",
    "    if not multi_class:\n",
    "        base_dir = os.path.join(os.path.dirname(predict_data_dir[0]), \"result\")\n",
    "    else:\n",
    "        base_dir = predict_data_dir[0]\n",
    "\n",
    "    # 2. Create the base directory: remove if it exists to start fresh, then create it\n",
    "    if os.path.isdir(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "    # 3. Create subdirectories within base_dir for each label to organize predictions\n",
    "    for label_folder in labels:\n",
    "        label_dir = os.path.join(base_dir, label_folder)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            os.mkdir(label_dir)\n",
    "\n",
    "    # Load the default font for annotation\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # 4. Loop over each image for prediction and annotation\n",
    "    for image_path in image_paths:\n",
    "        # Load and preprocess image: convert to RGB, resize to 150x150, normalize pixels\n",
    "        im = Image.open(image_path).convert('RGB')\n",
    "        im1 = im.resize((150, 150))\n",
    "        im1 = img_to_array(im1) / 255.0\n",
    "        im1 = np.expand_dims(im1, axis=0)\n",
    "\n",
    "        # Predict class probabilities with the model\n",
    "        pred = model.predict(im1)\n",
    "\n",
    "        # Prepare to draw annotations on the original image\n",
    "        draw = ImageDraw.Draw(im)\n",
    "\n",
    "        if multi_class:\n",
    "            # For multi-class, annotate each class probability on separate lines\n",
    "            y_text = 10\n",
    "            for i, label in enumerate(labels):\n",
    "                line = f\"{label}: {pred[0][i] * 100:.2f}%\"\n",
    "                draw.text((10, y_text), line, fill='red', font=font)\n",
    "                y_text += 15  # Move down for the next line\n",
    "        else:\n",
    "            # For single-class, annotate only the predicted label and confidence\n",
    "            max_idx = np.argmax(pred)\n",
    "            label = labels[max_idx]\n",
    "            confidence = pred[0][max_idx] * 100\n",
    "            draw.text((10, 10), f\"{label}\\n{confidence:.2f}%\", fill='red', font=font)\n",
    "\n",
    "        # Print predicted label and max confidence for logging\n",
    "        print(label, np.max(pred) * 100)\n",
    "\n",
    "        # Save annotated image only if prediction confidence exceeds threshold\n",
    "        if np.max(pred) * 100 >= threshold:\n",
    "            # Determine destination path based on classification mode\n",
    "            if multi_class:\n",
    "                max_idx = np.argmax(pred)\n",
    "                label = labels[max_idx]\n",
    "\n",
    "            dest_path = os.path.join(base_dir, label, f\"{nameImg}{os.path.splitext(image_path)[1]}\")\n",
    "\n",
    "            # Save the annotated image (not the original)\n",
    "            im.save(dest_path)\n",
    "\n",
    "            nameImg += 1\n",
    "\n",
    "\n",
    "# --- Execution section ---\n",
    "predict_image_paths = get_predict_image_paths(predict_data_dir)\n",
    "predict_and_annotate_images(model, predict_image_paths, label_list, multi_class, predict_data_dir)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S86fymVQuc21",
    "outputId": "63fed167-3b09-4dce-c3eb-4e72ebdf09cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Labels found: ['gohan', 'goku', 'piccolo', 'vegeta']\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 112ms/step\n",
      "goku 97.01141\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step\n",
      "goku 97.294716\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "goku 52.587883\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "vegeta 92.79697\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step\n",
      "gohan 34.16567\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "gohan 43.34923\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "goku 88.262344\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "vegeta 99.969635\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "vegeta 95.569534\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "goku 99.78293\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 76ms/step\n",
      "goku 34.320896\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step\n",
      "goku 98.55496\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
